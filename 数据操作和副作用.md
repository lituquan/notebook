## 数据覆盖  
今天用了replace into 命令，我当做update用了，导致数据表丢失了部分列，事故影响挺大的。

## 数据恢复
命令执行时间是：
2023-07-06 16:04:11

### 1.可用性修复：恢复到上个月的
replace into 命令执行的时候，用的是之前的数据。所以先用这部分恢复一个可以用的库表，应用正常了。
此时时间是：
2023-07-06 17:24:18

### 2.近乎同步数据恢复：恢复到到执行之前
运维同学从阿里云那边做了全库数据恢复，然后把对应的表记录同步到目标数据库。找到被更新的记录，update。
此时时间是：
2023-07-06 19:20:18

### 3.间接数据修复
由于上面的表有一个用户关联关系，在丢失关联期间。有不少kafkas数据记录没有被成功执行。看了代码和同事的文档了解到修复流程是：
1.解除数据已被消费限制：
key可能被消费，虽然失败。但是被记录过，这个需要从redis删除。

2.重新请求
线上提供了kafka和http两个处理方式，kafka重来会回拨所有的记录。为了避免副作用，直接执行http请求。

修复的数据准备：
1.从阿里云里面捞取指定时间段里面，被消费的数据记录日志。
2.解析日志，得到对应的请求和已被消费的key
3.生成http请求

这里我用python处理，比较快和简单。

## 反思
敬畏新技术，用replace into 命令之前想过改成update的，没及时处理。执行了这个。




