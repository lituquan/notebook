## 一、背景
日常增删改查，查询是常见的批量，一般会有分页。那如果需要计算、修改、插入大量数据怎么做呢？考虑用批处理+多线程。

## 二、批处理的场景
### 1.初始化数据+增量
服务增加了一个字段，数据来源于旧数据。需要将旧数据初始化，再配合一个增量同步。比如监听mq或者binlog。
还有一种情况，就是计算的数据除了要落库，还可能要同步给第三方，这时候瓶颈可能是第三方，比如腾讯企微平台是有限流的。
如果可以容忍限流，本地也限流，匹配第三方。当然，可以分离处理。处理办法：
本地数据先写，生成任务发送第三方，任务可以存数据库，标记状态即可，也可以落mq。

### 2.数据来自某个接口
本来计算的逻辑是单独使用的，某个新的需求要列表或者做聚合计算。为了提高性能，需要数据落库。

## 三、应对
考虑到任务可能耗时比较久，所以对任务做分割，比如1000条一个批次，记录批次下标，每个批次加上事务，失败回滚+重试。

分批之后，做到批次之间无依赖，可以使用多线程。

### 1.多任务
fork-join 结构

parallelStream  底层也是fork-join
    https://blog.csdn.net/Clearlove_S7/article/details/130183990

### 2.线程池
future/CompletableFuture, ExecutorService executor = Executors.newFixedThreadPool(10);
>https://juejin.cn/post/6970558076642394142

## 四、实现 
### demo
```java
@Slf4j
public abstract class DataBatch<T, K> {

    public int getBatchSize() {
        return 1000;
    }

    public void syncDataFromDc(Executor executor,List<T> intData) {
        int batchSize = getBatchSize(); // 每批次执行的任务数量
        Assert.isTrue(batchSize > 0, "batchSize 要大于0");
        Assert.notNull(executor);
        // 分批
        List<CompletableFuture<Void>> futures = new LinkedList<>();
        for (int i = 0; i < intData.size(); i += batchSize) {
            int endIndex = Math.min(i + batchSize, intData.size());
            final List<T> batchEntries = intData.subList(i, endIndex);
            final int id = i;
            CompletableFuture<Void> future = CompletableFuture.runAsync(() -> {
                // 计算
                List<K> results = handle(batchEntries);
                // 存储
                save(results);
            }, executor).exceptionally((e) -> {
                log.info("batch id:{}", id);
                e.printStackTrace();
                return null;
            });
            futures.add(future);
        }
        // 并发
        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();
    }

    // 存储
    public abstract void save(List<K> results);

    // 计算
    public abstract List<K> handle(List<T> intData);
}
```

### spring batch
上面的demo是手动实现数据分割、计算、存储。有没有开源方案呢，调研发现有个spring batch。
任务做了可靠性处理，但是单节点的。设计思路差不多，它分成：数据读取--数据处理【计算】--数据写入【存储】，比我的多了一步。
```java
@Bean
public Job importUserJob() {
    return jobBuilderFactory.get("importUserJob")
            .incrementer(new RunIdIncrementer())
            .flow(step1())
            .end()
            .build();
}

// 取数--计算--更新
private Step step1() {
    return stepBuilderFactory.get("step1")
            .<User, User>chunk(getBatchSize())
            .reader(reader())
            .processor(processor())
            .writer(writer())
            .build();
}
```

参考：
- 使用demo
https://juejin.cn/post/7239376445658103864
- 初始化
https://juejin.cn/post/6872006812439314446
- 多线程+并行
https://juejin.cn/post/7153234463063818271

### 数据同步框架
canal
    这个是监听binlog的，适合增量数据解析、实时监听，正常情况会有的时差是几秒钟，碰到主从库有延迟、MQ消费慢，时长会增加。之前使用过，有2个坑：
        大量数据修改，会产生大量没用的消息事件；
        应对数据库表更改有问题，会导致事件停止产生，这个是因为有个元数据文件是启动的时候加载的，修改之后会导致数据解析不了。

kettle  
    这个目前Bi在用，应该是比较合适的，有一定的学习成本。
    
    job定时
       第一种是kettle自带的Start控件，缺点是kettle程序必须始终运行，浪费内存。
       第二种是使用系统的定时功能。使用Kitchen、Pan命令编写bat、sh脚本，然后使用windows任务计划或者linux的crotab实现定时执行执行脚本。
        
       分布式：xxl-job，https://blog.csdn.net/weixin_36063646/article/details/101285267
    
    结合spring:
        https://juejin.cn/post/7187568850366365755

datax
    这个还没用过~

### 大数据 job: hadoop MR 模型
大数据的任务分割，多个map，多个reduce。